{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fa647d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:24:20.991887Z",
     "start_time": "2023-04-09T19:23:18.461080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Using cached tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.53.0-cp39-cp39-win_amd64.whl (4.0 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Using cached ml_dtypes-0.0.4-cp39-cp39-win_amd64.whl (97 kB)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.2-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91880\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: numpy, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, opt-einsum, ml-dtypes, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 gast-0.4.0 google-auth-2.17.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.53.0 jax-0.4.8 ml-dtypes-0.0.4 numpy-1.23.5 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.12.1 tensorflow-2.12.0 tensorflow-intel-2.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.5 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\91880\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a61125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:24:30.462260Z",
     "start_time": "2023-04-09T19:24:20.991887Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c90ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:25:10.032582Z",
     "start_time": "2023-04-09T19:25:09.954423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestfires = pd.read_csv('forestfires.csv')\n",
    "\n",
    "\n",
    "forestfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ec4385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:26:11.431941Z",
     "start_time": "2023-04-09T19:26:11.369481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = forestfires.iloc[:,2:30]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73beb4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:27:12.942393Z",
     "start_time": "2023-04-09T19:27:12.911090Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef37470d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:28:24.071695Z",
     "start_time": "2023-04-09T19:28:24.039778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(data1)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5d4dba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:29:16.950179Z",
     "start_time": "2023-04-09T19:29:16.935015Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa618ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:29:54.473597Z",
     "start_time": "2023-04-09T19:29:54.302068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  1.30619034e-14, -1.63267504e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02,  4.68082711e-15, -4.51925684e-16],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  4.39226511e-15, -2.00039593e-16],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01,  3.29069057e-17,  3.06608857e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02,  5.35070622e-16,  1.08857027e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  1.24763181e-16,  7.68823392e-17]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=28)\n",
    "pca_values = pca.fit_transform(x)\n",
    "\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba47f264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:30:40.289285Z",
     "start_time": "2023-04-09T19:30:40.258297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 2.12618672e-33])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e192ebf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:31:32.218896Z",
     "start_time": "2023-04-09T19:31:32.210378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var,decimals=4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59d74df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:31:49.596318Z",
     "start_time": "2023-04-09T19:31:48.579747Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f7920c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:32:21.565035Z",
     "start_time": "2023-04-09T19:32:21.346240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae39ac68b0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3be23ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:33:02.981967Z",
     "start_time": "2023-04-09T19:33:02.966399Z"
    }
   },
   "outputs": [],
   "source": [
    "#TAKING PCA AS 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "773473aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:38:23.124343Z",
     "start_time": "2023-04-09T19:38:23.046069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data=pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                 forestfires[['size_category']]], axis = 1)\n",
    "final_data.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac41b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:38:49.522815Z",
     "start_time": "2023-04-09T19:38:49.507369Z"
    }
   },
   "outputs": [],
   "source": [
    "array = final_data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83a8f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:39:29.328749Z",
     "start_time": "2023-04-09T19:39:29.312698Z"
    }
   },
   "outputs": [],
   "source": [
    "x = array[:,0:24]\n",
    "y = array[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb73eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:39:31.600361Z",
     "start_time": "2023-04-09T19:39:31.569397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947, -1.32025451, -0.8439714 , ..., -0.40542518,\n",
       "        -0.11871871, -0.01793327],\n",
       "       [ 0.39078626,  0.83106152, -1.10136513, ...,  0.83659019,\n",
       "         0.20497507,  0.29077058],\n",
       "       [ 0.6904156 ,  1.17774562, -1.22199841, ...,  0.7436481 ,\n",
       "         0.08175698,  0.34591549],\n",
       "       ...,\n",
       "       [ 0.921634  , -0.26454307,  2.71921606, ..., -1.73671092,\n",
       "        -1.15412738, -1.23004047],\n",
       "       [-1.62054896, -0.97883823,  0.33198736, ..., -0.05554841,\n",
       "        -0.06750183, -0.31102687],\n",
       "       [ 4.07590654, -0.36744073, -0.24715178, ...,  1.04284992,\n",
       "         0.29643602,  0.12509878]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a3a531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:39:35.807750Z",
     "start_time": "2023-04-09T19:39:35.776701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c55cb538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:40:44.947735Z",
     "start_time": "2023-04-09T19:40:44.926888Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5dad825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:42:46.790289Z",
     "start_time": "2023-04-09T19:42:21.892275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 1s 8ms/step - loss: 0.7442 - accuracy: 0.5402 - val_loss: 0.6834 - val_accuracy: 0.6218\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.6898 - val_loss: 0.6542 - val_accuracy: 0.7179\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.7341 - val_loss: 0.6440 - val_accuracy: 0.7051\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7452 - val_loss: 0.6387 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7618 - val_loss: 0.6397 - val_accuracy: 0.6859\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7701 - val_loss: 0.6370 - val_accuracy: 0.6859\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7729 - val_loss: 0.6388 - val_accuracy: 0.6987\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7729 - val_loss: 0.6400 - val_accuracy: 0.6923\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7756 - val_loss: 0.6427 - val_accuracy: 0.6923\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7756 - val_loss: 0.6429 - val_accuracy: 0.6923\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7756 - val_loss: 0.6451 - val_accuracy: 0.7051\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7756 - val_loss: 0.6494 - val_accuracy: 0.7051\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7756 - val_loss: 0.6501 - val_accuracy: 0.7115\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7756 - val_loss: 0.6499 - val_accuracy: 0.7115\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7756 - val_loss: 0.6520 - val_accuracy: 0.7115\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7756 - val_loss: 0.6584 - val_accuracy: 0.7115\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.6555 - val_accuracy: 0.6987\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.6554 - val_accuracy: 0.6987\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.6576 - val_accuracy: 0.6987\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7812 - val_loss: 0.6607 - val_accuracy: 0.7051\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.6650 - val_accuracy: 0.7115\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7895 - val_loss: 0.6599 - val_accuracy: 0.7051\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7978 - val_loss: 0.6600 - val_accuracy: 0.7051\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8006 - val_loss: 0.6527 - val_accuracy: 0.7051\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8033 - val_loss: 0.6579 - val_accuracy: 0.7051\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.7978 - val_loss: 0.6558 - val_accuracy: 0.7115\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8061 - val_loss: 0.6563 - val_accuracy: 0.7115\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8144 - val_loss: 0.6582 - val_accuracy: 0.7115\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8116 - val_loss: 0.6597 - val_accuracy: 0.7179\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8172 - val_loss: 0.6598 - val_accuracy: 0.7308\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8255 - val_loss: 0.6598 - val_accuracy: 0.7436\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8283 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8532 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8560 - val_loss: 0.6602 - val_accuracy: 0.7564\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8753 - val_loss: 0.6626 - val_accuracy: 0.7564\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8615 - val_loss: 0.6710 - val_accuracy: 0.7436\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8726 - val_loss: 0.6710 - val_accuracy: 0.7372\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8781 - val_loss: 0.6723 - val_accuracy: 0.7372\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8781 - val_loss: 0.6712 - val_accuracy: 0.7308\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8809 - val_loss: 0.6808 - val_accuracy: 0.7372\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8726 - val_loss: 0.6829 - val_accuracy: 0.7372\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8864 - val_loss: 0.6829 - val_accuracy: 0.7436\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8837 - val_loss: 0.6848 - val_accuracy: 0.7372\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8892 - val_loss: 0.6911 - val_accuracy: 0.7308\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8920 - val_loss: 0.6908 - val_accuracy: 0.7372\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.9058 - val_loss: 0.6892 - val_accuracy: 0.7436\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.9197 - val_loss: 0.6971 - val_accuracy: 0.7436\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.9086 - val_loss: 0.6961 - val_accuracy: 0.7628\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9114 - val_loss: 0.6937 - val_accuracy: 0.7628\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.9058 - val_loss: 0.6942 - val_accuracy: 0.7628\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9224 - val_loss: 0.7010 - val_accuracy: 0.7628\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9141 - val_loss: 0.7128 - val_accuracy: 0.7500\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9252 - val_loss: 0.7124 - val_accuracy: 0.7564\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.9307 - val_loss: 0.7103 - val_accuracy: 0.7628\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2176 - accuracy: 0.9280 - val_loss: 0.7133 - val_accuracy: 0.7564\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9280 - val_loss: 0.7229 - val_accuracy: 0.7628\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2178 - accuracy: 0.9197 - val_loss: 0.7468 - val_accuracy: 0.7756\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9363 - val_loss: 0.7260 - val_accuracy: 0.7821\n",
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9363 - val_loss: 0.7299 - val_accuracy: 0.7756\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9363 - val_loss: 0.7267 - val_accuracy: 0.7821\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9446 - val_loss: 0.7362 - val_accuracy: 0.7692\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9418 - val_loss: 0.7359 - val_accuracy: 0.7692\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9418 - val_loss: 0.7462 - val_accuracy: 0.7692\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9474 - val_loss: 0.7490 - val_accuracy: 0.7692\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9474 - val_loss: 0.7516 - val_accuracy: 0.7692\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9391 - val_loss: 0.7576 - val_accuracy: 0.7692\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9474 - val_loss: 0.7639 - val_accuracy: 0.7756\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9501 - val_loss: 0.7629 - val_accuracy: 0.7756\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9474 - val_loss: 0.7699 - val_accuracy: 0.7821\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9501 - val_loss: 0.7578 - val_accuracy: 0.7821\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9529 - val_loss: 0.7810 - val_accuracy: 0.7821\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9584 - val_loss: 0.7881 - val_accuracy: 0.7885\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9529 - val_loss: 0.7877 - val_accuracy: 0.7885\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9557 - val_loss: 0.7949 - val_accuracy: 0.7821\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9557 - val_loss: 0.7996 - val_accuracy: 0.7821\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.9584 - val_loss: 0.8096 - val_accuracy: 0.7756\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9584 - val_loss: 0.8104 - val_accuracy: 0.7756\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9612 - val_loss: 0.8121 - val_accuracy: 0.7756\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.9557 - val_loss: 0.8260 - val_accuracy: 0.7756\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9584 - val_loss: 0.8380 - val_accuracy: 0.7756\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9584 - val_loss: 0.8314 - val_accuracy: 0.7756\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9584 - val_loss: 0.8420 - val_accuracy: 0.7692\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9612 - val_loss: 0.8614 - val_accuracy: 0.7692\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9612 - val_loss: 0.8546 - val_accuracy: 0.7756\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9668 - val_loss: 0.8593 - val_accuracy: 0.7628\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9612 - val_loss: 0.8550 - val_accuracy: 0.7628\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9584 - val_loss: 0.8658 - val_accuracy: 0.7692\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9668 - val_loss: 0.8752 - val_accuracy: 0.7692\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9668 - val_loss: 0.8847 - val_accuracy: 0.7756\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9668 - val_loss: 0.8821 - val_accuracy: 0.7628\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9668 - val_loss: 0.8915 - val_accuracy: 0.7692\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9695 - val_loss: 0.8919 - val_accuracy: 0.7564\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9695 - val_loss: 0.9017 - val_accuracy: 0.7692\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9668 - val_loss: 0.9100 - val_accuracy: 0.7628\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9695 - val_loss: 0.9294 - val_accuracy: 0.7500\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9695 - val_loss: 0.9271 - val_accuracy: 0.7564\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9751 - val_loss: 0.9266 - val_accuracy: 0.7564\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.9294 - val_accuracy: 0.7564\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9723 - val_loss: 0.9382 - val_accuracy: 0.7692\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9751 - val_loss: 0.9442 - val_accuracy: 0.7564\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9778 - val_loss: 0.9424 - val_accuracy: 0.7628\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9751 - val_loss: 0.9487 - val_accuracy: 0.7564\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9751 - val_loss: 0.9461 - val_accuracy: 0.7628\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9806 - val_loss: 0.9619 - val_accuracy: 0.7564\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9806 - val_loss: 0.9721 - val_accuracy: 0.7564\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.9600 - val_accuracy: 0.7692\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9834 - val_loss: 0.9580 - val_accuracy: 0.7692\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9834 - val_loss: 0.9773 - val_accuracy: 0.7628\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9806 - val_loss: 0.9825 - val_accuracy: 0.7692\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9861 - val_loss: 0.9874 - val_accuracy: 0.7692\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9861 - val_loss: 0.9983 - val_accuracy: 0.7692\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9889 - val_loss: 1.0014 - val_accuracy: 0.7756\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9889 - val_loss: 1.0203 - val_accuracy: 0.7821\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9861 - val_loss: 1.0224 - val_accuracy: 0.7692\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 1.0399 - val_accuracy: 0.7756\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9834 - val_loss: 1.0371 - val_accuracy: 0.7821\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 1.0403 - val_accuracy: 0.7821\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9889 - val_loss: 1.0621 - val_accuracy: 0.7821\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 1.0675 - val_accuracy: 0.7628\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9917 - val_loss: 1.0678 - val_accuracy: 0.7692\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9889 - val_loss: 1.0848 - val_accuracy: 0.7692\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9917 - val_loss: 1.0807 - val_accuracy: 0.7885\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9889 - val_loss: 1.1017 - val_accuracy: 0.7885\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9917 - val_loss: 1.1165 - val_accuracy: 0.7756\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9834 - val_loss: 1.1222 - val_accuracy: 0.7756\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9889 - val_loss: 1.1209 - val_accuracy: 0.7885\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9917 - val_loss: 1.1297 - val_accuracy: 0.7885\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9889 - val_loss: 1.1509 - val_accuracy: 0.7756\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9972 - val_loss: 1.1544 - val_accuracy: 0.7756\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9917 - val_loss: 1.1592 - val_accuracy: 0.7756\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 1.1745 - val_accuracy: 0.7756\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 1.1868 - val_accuracy: 0.7756\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9972 - val_loss: 1.1911 - val_accuracy: 0.7756\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 1.1932 - val_accuracy: 0.7756\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9945 - val_loss: 1.2107 - val_accuracy: 0.7756\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9945 - val_loss: 1.2224 - val_accuracy: 0.7756\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 1.2334 - val_accuracy: 0.7756\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 1.2460 - val_accuracy: 0.7756\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 1.2521 - val_accuracy: 0.7756\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 1.2454 - val_accuracy: 0.7756\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9945 - val_loss: 1.2737 - val_accuracy: 0.7756\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9972 - val_loss: 1.2780 - val_accuracy: 0.7756\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 1.2999 - val_accuracy: 0.7756\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9945 - val_loss: 1.3151 - val_accuracy: 0.7756\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9945 - val_loss: 1.3181 - val_accuracy: 0.7756\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 1.3205 - val_accuracy: 0.7756\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9972 - val_loss: 1.3288 - val_accuracy: 0.7756\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 1.3319 - val_accuracy: 0.7756\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9972 - val_loss: 1.3525 - val_accuracy: 0.7756\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9972 - val_loss: 1.3750 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae464c94f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x,y, validation_split=0.3,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94d5f337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:45:20.193202Z",
     "start_time": "2023-04-09T19:45:20.068147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "#accuracy of model\n",
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4ed41ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:46:06.415180Z",
     "start_time": "2023-04-09T19:45:55.359158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 3.7601 - accuracy: 0.7562 - val_loss: 5.0428 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae4c8552e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Dense(12,input_dim=24,activation='sigmoid'))\n",
    "model1.add(Dense(8,activation='sigmoid'))\n",
    "model1.add(Dense(1,activation='relu'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model1.fit(x, y, validation_split=0.3, epochs=100, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fed42f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:46:19.865248Z",
     "start_time": "2023-04-09T19:46:19.723665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 4.1471 - accuracy: 0.7311\n"
     ]
    }
   ],
   "source": [
    "scores1=model1.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "246f5836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:46:43.589450Z",
     "start_time": "2023-04-09T19:46:30.766206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 1.7458 - accuracy: 0.6814 - val_loss: 2.5842 - val_accuracy: 0.5897\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3267 - accuracy: 0.6953 - val_loss: 2.4679 - val_accuracy: 0.6154\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.7175 - val_loss: 2.2968 - val_accuracy: 0.6282\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2132 - accuracy: 0.7230 - val_loss: 2.2847 - val_accuracy: 0.6218\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2004 - accuracy: 0.7368 - val_loss: 2.2815 - val_accuracy: 0.6154\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0580 - accuracy: 0.7341 - val_loss: 2.0278 - val_accuracy: 0.6026\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0044 - accuracy: 0.7091 - val_loss: 1.8575 - val_accuracy: 0.5962\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9814 - accuracy: 0.7313 - val_loss: 1.9391 - val_accuracy: 0.6282\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9691 - accuracy: 0.7396 - val_loss: 1.9648 - val_accuracy: 0.6282\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9590 - accuracy: 0.7368 - val_loss: 2.0162 - val_accuracy: 0.6282\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9258 - accuracy: 0.7507 - val_loss: 1.6050 - val_accuracy: 0.6218\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8330 - accuracy: 0.7562 - val_loss: 1.6033 - val_accuracy: 0.6346\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7562 - val_loss: 1.3674 - val_accuracy: 0.6410\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7645 - val_loss: 1.3787 - val_accuracy: 0.6474\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7673 - val_loss: 1.4599 - val_accuracy: 0.6410\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7729 - val_loss: 1.4476 - val_accuracy: 0.6410\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7784 - val_loss: 1.4564 - val_accuracy: 0.6538\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7784 - val_loss: 1.4524 - val_accuracy: 0.6538\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7784 - val_loss: 1.5329 - val_accuracy: 0.6538\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7784 - val_loss: 1.5309 - val_accuracy: 0.6603\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7756 - val_loss: 1.4705 - val_accuracy: 0.6603\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7867 - val_loss: 1.5264 - val_accuracy: 0.6603\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7867 - val_loss: 1.4584 - val_accuracy: 0.6474\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7922 - val_loss: 1.5211 - val_accuracy: 0.6474\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7839 - val_loss: 1.5237 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.8006 - val_loss: 1.5171 - val_accuracy: 0.6474\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.8006 - val_loss: 1.5289 - val_accuracy: 0.6538\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.8033 - val_loss: 1.5474 - val_accuracy: 0.6538\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.8089 - val_loss: 1.5210 - val_accuracy: 0.6603\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5090 - accuracy: 0.8116 - val_loss: 1.6043 - val_accuracy: 0.6795\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8061 - val_loss: 1.5397 - val_accuracy: 0.6795\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.8033 - val_loss: 1.6120 - val_accuracy: 0.6795\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.8116 - val_loss: 1.5017 - val_accuracy: 0.6859\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8144 - val_loss: 1.5168 - val_accuracy: 0.6987\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8172 - val_loss: 1.6889 - val_accuracy: 0.6987\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8227 - val_loss: 1.6817 - val_accuracy: 0.6859\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8255 - val_loss: 1.6931 - val_accuracy: 0.6923\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8172 - val_loss: 1.7597 - val_accuracy: 0.6987\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8172 - val_loss: 1.7562 - val_accuracy: 0.6923\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8227 - val_loss: 1.6827 - val_accuracy: 0.6923\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8366 - val_loss: 1.6058 - val_accuracy: 0.6923\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8421 - val_loss: 1.6824 - val_accuracy: 0.7051\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8283 - val_loss: 1.7352 - val_accuracy: 0.6987\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8338 - val_loss: 1.7782 - val_accuracy: 0.6859\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8255 - val_loss: 1.7819 - val_accuracy: 0.6859\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8310 - val_loss: 1.7023 - val_accuracy: 0.6859\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8421 - val_loss: 1.6938 - val_accuracy: 0.6859\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8393 - val_loss: 1.7060 - val_accuracy: 0.6923\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8393 - val_loss: 1.7158 - val_accuracy: 0.6987\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8449 - val_loss: 1.7860 - val_accuracy: 0.6987\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8421 - val_loss: 1.7082 - val_accuracy: 0.6987\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8393 - val_loss: 1.8776 - val_accuracy: 0.6987\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8393 - val_loss: 1.8683 - val_accuracy: 0.6987\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8449 - val_loss: 1.7997 - val_accuracy: 0.7115\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8615 - val_loss: 1.5325 - val_accuracy: 0.6923\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8670 - val_loss: 1.6602 - val_accuracy: 0.6987\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8587 - val_loss: 1.7129 - val_accuracy: 0.6987\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8504 - val_loss: 1.7219 - val_accuracy: 0.6987\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8643 - val_loss: 1.7005 - val_accuracy: 0.6987\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8698 - val_loss: 1.7093 - val_accuracy: 0.6923\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8698 - val_loss: 1.7494 - val_accuracy: 0.7051\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8698 - val_loss: 1.6749 - val_accuracy: 0.7051\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8698 - val_loss: 1.8005 - val_accuracy: 0.6795\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8809 - val_loss: 1.7588 - val_accuracy: 0.6923\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8864 - val_loss: 1.8783 - val_accuracy: 0.6859\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8781 - val_loss: 1.9912 - val_accuracy: 0.6987\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8781 - val_loss: 1.8100 - val_accuracy: 0.6923\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8864 - val_loss: 1.9157 - val_accuracy: 0.6923\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8837 - val_loss: 1.9460 - val_accuracy: 0.7051\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8947 - val_loss: 1.8142 - val_accuracy: 0.7051\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8837 - val_loss: 1.8791 - val_accuracy: 0.7115\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8920 - val_loss: 1.9374 - val_accuracy: 0.7115\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8947 - val_loss: 2.0115 - val_accuracy: 0.7051\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8809 - val_loss: 2.0211 - val_accuracy: 0.7051\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.8975 - val_loss: 1.8517 - val_accuracy: 0.6987\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.9030 - val_loss: 1.8661 - val_accuracy: 0.6987\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3035 - accuracy: 0.9003 - val_loss: 1.8614 - val_accuracy: 0.7115\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.9003 - val_loss: 1.7680 - val_accuracy: 0.7115\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9058 - val_loss: 1.8355 - val_accuracy: 0.7115\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.9114 - val_loss: 1.9221 - val_accuracy: 0.7115\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.9030 - val_loss: 1.9295 - val_accuracy: 0.7115\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.9058 - val_loss: 1.9229 - val_accuracy: 0.7115\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8975 - val_loss: 1.9278 - val_accuracy: 0.7115\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.9114 - val_loss: 1.9160 - val_accuracy: 0.7115\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.9169 - val_loss: 1.8576 - val_accuracy: 0.7115\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.9141 - val_loss: 1.8478 - val_accuracy: 0.7179\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.2762 - accuracy: 0.9197 - val_loss: 1.8500 - val_accuracy: 0.7179\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2757 - accuracy: 0.9169 - val_loss: 1.8417 - val_accuracy: 0.7179\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2721 - accuracy: 0.9169 - val_loss: 1.7871 - val_accuracy: 0.7179\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2683 - accuracy: 0.9197 - val_loss: 1.9229 - val_accuracy: 0.7179\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2704 - accuracy: 0.9280 - val_loss: 1.8804 - val_accuracy: 0.6923\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9169 - val_loss: 1.7102 - val_accuracy: 0.7244\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9197 - val_loss: 1.8231 - val_accuracy: 0.6859\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9169 - val_loss: 1.7653 - val_accuracy: 0.6987\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9169 - val_loss: 1.6766 - val_accuracy: 0.7051\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.9224 - val_loss: 1.7754 - val_accuracy: 0.6923\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9252 - val_loss: 1.8295 - val_accuracy: 0.7051\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2231 - accuracy: 0.9280 - val_loss: 2.0474 - val_accuracy: 0.7115\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9307 - val_loss: 1.9477 - val_accuracy: 0.7244\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9307 - val_loss: 1.7722 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae46059ac0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model2.add(Dense(8,activation='relu'))\n",
    "model2.add(Dense(1,activation='relu'))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(x,y,epochs=100, validation_split=0.3,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4ef81dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:47:19.704944Z",
     "start_time": "2023-04-09T19:47:19.532075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.8704\n"
     ]
    }
   ],
   "source": [
    "scores2 = model2.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8984463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T19:48:38.654470Z",
     "start_time": "2023-04-09T19:48:38.623182Z"
    }
   },
   "outputs": [],
   "source": [
    "#ABOVE ALL 1ST MODEL IS THE ONE WHICH GIVES BEST ACCURACY OF 93.04%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966a7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
